# web_tool/views.py
# -*- coding: utf-8 -*-
import io, csv, re, sqlite3
from pathlib import Path
import pandas as pd

from django.http import JsonResponse, HttpResponseBadRequest, HttpResponse
from django.shortcuts import render
from django.views.decorators.http import require_POST, require_GET

# MME å·¥å…·
from .utils.mme_pipline import run_pipeline, save_append

# IEDB æ ¸å¿ƒå‡½å¼
from .utils.IEDB_pipline import process as iedb_process

# åˆ†é å·¥å…·
from .utils.View_by_Epitope import build_view_by_epitope
from web_tool.utils.view_by_query import build_summary_by_query, DB_PATH

# ç”¢ç”ŸJOB_ID
from .utils.jobs import create_job

# ---------------------------------------------------------
# å¸¸æ•¸è¨­å®š
# ---------------------------------------------------------
# åƒè€ƒè³‡æ–™ FASTAï¼ˆè«‹ç¢ºèªæª”æ¡ˆå­˜åœ¨ï¼‰
HUMAN_FASTA = Path(__file__).resolve().parent / "static" / "web_tool" / "ref" / "human.fasta"

# IEDB åƒè€ƒ CSVï¼ˆè·¯å¾‘å»ºè­°ç”¨ç›¸å°æœ¬ app çš„æ–¹å¼ï¼Œä¸æ€•æ›æ©Ÿï¼‰
IEDB_CSV = str(
    Path(__file__).resolve().parent / "static" / "web_tool" / "ref" / "IEDB_human_correct.csv"
)

# SQLite æª”ï¼ˆçµ±ä¸€éƒ½å¯«åˆ°é€™å€‹ DBï¼‰
DB_PATH   = r"C:\Users\ethan\Desktop\ç¢©ç­\æš‘å‡\web_hw\web_hw\hw1\hw1\iedb_result.sqlite3"
TABLE_RAW = "mme_result"     # åŸå§‹ MME
TABLE_ENR = "iedb_result"    # IEDB enriched
VIEW_EPI_TABLE = "view_by_epitope"
# Detailé é¢
TABLE_IEDB_PROOFED = "IEDB_human_correct"

# ---------------------------------------------------------
# é¦–é 
# ---------------------------------------------------------
def mme_form_page(request):
    return render(request, "hw.html")

# ---------------------------------------------------------
# å…±ç”¨å°å·¥å…·
# ---------------------------------------------------------
def _sanitize_columns(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    out.columns = [re.sub(r'[^0-9a-zA-Z_]+', '_', c).strip('_').lower() for c in out.columns]
    return out

def _save_iedb_enriched(df_enr: pd.DataFrame) -> int:
    """å¯«å…¥ TABLE_ENRï¼ˆsnake_case æ¬„ä½ï¼‰ï¼Œå›å‚³æœ¬æ¬¡å¯«å…¥ç­†æ•¸"""
    sdf = _sanitize_columns(df_enr)
    n_added = len(sdf)
    Path(DB_PATH).parent.mkdir(parents=True, exist_ok=True)
    with sqlite3.connect(DB_PATH) as conn:
        conn.execute("PRAGMA journal_mode=WAL;")
        conn.execute("PRAGMA synchronous=NORMAL;")
        conn.execute("PRAGMA foreign_keys=ON;")
        sdf.to_sql(TABLE_ENR, conn, if_exists="append", index=False)
    return n_added

# ---------------------------------------------------------
# å¾Œç«¯ APIï¼šè¡¨å–®æäº¤ â†’ è·‘ MME & IEDB â†’ å­˜ DB â†’ å¾ DB è®€å›ç•¶æ‰¹ â†’ å› JSON/CSV
# ---------------------------------------------------------
@require_POST
def mme_form(request):
    is_ajax = request.headers.get("x-requested-with") == "XMLHttpRequest"

    # 1) é©—è­‰ k
    k_str = (request.POST.get("k_mer") or "").strip()
    if not k_str:
        return HttpResponseBadRequest("è«‹è¼¸å…¥ k-mer é•·åº¦")
    try:
        k = int(k_str)
    except ValueError:
        return HttpResponseBadRequest("k-mer å¿…é ˆæ˜¯æ•´æ•¸")
    if not (1 <= k <= 1000):
        return HttpResponseBadRequest("k-mer å¿…é ˆä»‹æ–¼ 1 åˆ° 1000 ä¹‹é–“")

    # 2) species èˆ‡ human fasta
    species = request.POST.get("species", "human")
    if species != "human":
        return HttpResponseBadRequest("ç›®å‰åƒ…æ”¯æ´ human åƒè€ƒè³‡æ–™")
    human_path = str(HUMAN_FASTA)
    if not Path(human_path).exists():
        return HttpResponseBadRequest(f"åƒè€ƒ FASTA ä¸å­˜åœ¨ï¼š{human_path}")

    # 3) å–å¾— queryï¼ˆæª”æ¡ˆå„ªå…ˆï¼Œå¦å‰‡ textareaï¼‰
    up = request.FILES.get("query_fasta")
    txt = (request.POST.get("query_fasta") or "").strip()
    if not up and not txt:
        return HttpResponseBadRequest("è«‹è²¼ä¸Š FASTA æˆ–ä¸Šå‚³æª”æ¡ˆ")

    if up:
        raw = up.read()
        try:
            q_text = raw.decode("utf-8")
        except UnicodeDecodeError:
            q_text = raw.decode("utf-8", errors="ignore")
    else:
        q_text = txt
    q_file_like = io.StringIO(q_text)

    # 4) è·‘ MME
    try:
        df_raw = run_pipeline(q_file_like, human_path, k=k)
    except Exception as e:
        return HttpResponseBadRequest(f"é‹è¡Œå¤±æ•—ï¼š{e}")

    # 5) ï¼ˆå¯é¸ï¼‰å­˜åŸå§‹ MME
    try:
        save_append(df_raw, db_path=DB_PATH, table=TABLE_RAW)
    except Exception as e:
        # å¯«åº«å¤±æ•—ä¸å½±éŸ¿å›æ‡‰ IEDB çµæœ
        print(f"âš ï¸ å¯«å…¥ {TABLE_RAW} å¤±æ•—ï¼š{e}", flush=True)

    # 6) è·‘ IEDB enrich
    try:
        iedb_df = pd.read_csv(IEDB_CSV, encoding="utf-8-sig")
    except Exception as e:
        return HttpResponseBadRequest(f"è®€å– IEDB CSV å¤±æ•—ï¼š{e}")
    try:
        df_enr = iedb_process(df_raw.copy(), iedb_df)
    except Exception as e:
        return HttpResponseBadRequest(f"IEDB é‹è¡Œå¤±æ•—ï¼š{e}")

    # 7) å­˜ IEDB enrichedï¼ˆä¸åŠ  batch_idï¼‰
    n_added = _save_iedb_enriched(df_enr)

    # 7.1) â˜… è‡ªå‹•é‡å»º view_by_epitopeï¼ˆè‹¥å·¥å…·æ”¯æ´ï¼‰
    try:
        build_view_by_epitope(DB_PATH, src_table=TABLE_ENR, dst_table=VIEW_EPI_TABLE)
    except Exception as e:
        print(f"âš ï¸ é‡å»º {VIEW_EPI_TABLE} å¤±æ•—ï¼š{e}", flush=True)
        
    # 8) å¾ DB è®€å›ã€Œæœ¬æ‰¹ã€è³‡æ–™ï¼šç”¨ rowid å€’åºå–æœ€æ–° n_added ç­†ï¼Œå†åè½‰å›åŸé †åº
    with sqlite3.connect(DB_PATH) as conn:
        df_show = pd.read_sql(
            f'SELECT * FROM "{TABLE_ENR}" ORDER BY rowid DESC LIMIT ?',
            conn, params=[n_added]
        )
    
    # ğŸ”¹æŠŠ batch_id å¾å›å‚³çµæœç§»é™¤ï¼ˆèˆŠè³‡æ–™ç«‹åˆ»ä¸é¡¯ç¤ºï¼‰
    df_show = df_show.drop(columns=["batch_id"], errors="ignore")
    
    # åè½‰å›å¯«å…¥é †åºï¼ˆå¯é¸ï¼‰
    if not df_show.empty:
        df_show = df_show.iloc[::-1].reset_index(drop=True)

    # 9) å›å‚³
    if is_ajax:
        return JsonResponse({
            "source": "iedb_enriched",
            "db_path": DB_PATH,
            "table": TABLE_ENR,
            "columns": list(df_show.columns),
            "records": df_show.to_dict(orient="records"),
        }, safe=False)

    csv_text = df_show.to_csv(index=False)
    resp = HttpResponse(csv_text, content_type="text/csv; charset=utf-8")
    resp["Content-Disposition"] = f'attachment; filename="iedb_enriched_k{k}.csv"'
    return resp

# ---------------------------------------------------------
# JOB_ID
# ---------------------------------------------------------
@require_GET
def api_create_job(request):
    """
    è¼•é‡ï¼šä¸éœ€åƒæ•¸ã€‚ç¬¬ä¸€æ¬¡é€²ä¸»é æ™‚å«ä¸€æ¬¡ï¼Œæ‹¿åˆ°ä¸€çµ„ jobã€‚
    ä¹‹å¾Œå­˜åœ¨ localStorage å°±ä¸å†å«ã€‚
    """
    job = create_job(params={})  # ä½ è¦æ”¾ä»€éº¼é è¨­åƒæ•¸éƒ½å¯ä»¥
    return JsonResponse(job)

def job_id_search(request):
    return render(request, "job_id_search.html")
# ---------------------------------------------------------
# é¡¯ç¤ºé ï¼ˆDataTables å®¹å™¨ï¼‰
# ---------------------------------------------------------
def View_Perfect_Match_Table(request):
    return render(request, "Perfect_Table.html")

def View_by_Eptiope(request):
    return render(request, "view_by_eptiope.html")

def View_by_Query(request):
    return render(request, "view_by_query.html")

def View_by_Reference(request):
    return render(request, "view_by_reference.html")

def reference_detail(request, id):
    return render(request, "web_tool/view_by_ref_detail.html", {"id": id})
# ---------------------------------------------------------
# æä¾› IEDB çµæœçš„ JSONï¼ˆå¦‚æœä½ æœ‰ç¨ç«‹é é¢éœ€è¦ç›´æ¥è®€ DB é¡¯ç¤ºï¼‰
# ---------------------------------------------------------
@require_GET
def iedb_from_sqlite(request):
    """è®€ DB çš„ IEDB enrichedï¼ˆTABLE_ENRï¼‰â†’ å› {columns, records}"""
    limit = request.GET.get("limit")
    limit = int(limit) if (limit and str(limit).isdigit()) else None

    sql = f'SELECT * FROM "{TABLE_ENR}"'
    if limit is not None:
        sql += f" LIMIT {limit}"

    try:
        with sqlite3.connect(DB_PATH) as conn:
            df = pd.read_sql(sql, conn)
    except Exception as e:
        return HttpResponseBadRequest(f"è®€å– SQLite å¤±æ•—ï¼š{e}")

    return JsonResponse({
        "columns": list(df.columns),
        "records": df.to_dict(orient="records")
    }, safe=False)

@require_GET
def View_by_Epitope_data(request):
    # å¯é¸ï¼šä¾ query_protein_name / epitope ç¯©
    q   = (request.GET.get("q") or "").strip()
    epi = (request.GET.get("epitope") or "").strip()
    lim = (request.GET.get("limit") or "").strip()
    limit = int(lim) if lim.isdigit() else None

    try:
        with sqlite3.connect(DB_PATH) as conn:
            # é€™è£¡æ”¹æŸ¥ã€ŒçœŸå¯¦è¡¨ã€TABLE_ENRï¼ˆ= iedb_resultï¼‰ï¼Œä¸è¦ç”¨ VIEW_EPI_TABLE
            # å› ç‚ºæˆ‘å€‘è¦çš„æ¬„ä½èˆ‡æ­£ç¢ºçš„èšåˆå£å¾‘éƒ½åœ¨çœŸå¯¦è¡¨è£¡ã€‚
            cols = [r[1] for r in conn.execute(f'PRAGMA table_info("{TABLE_ENR}")')]
            needed = {"mme_query", "query_protein_name", "hit_human_protein_id", "iedb_human_epitope_substring_count"}
            missing = sorted(list(needed - set(cols)))
            if missing:
                return HttpResponseBadRequest(f"è¡¨ '{TABLE_ENR}' ç¼ºå°‘æ¬„ä½ï¼š{missing}ã€‚ç›®å‰æ¬„ä½ï¼š{cols}")

            # WHEREï¼ˆåƒ…ä½œç‚ºå‰ç½®ç¯©é¸ï¼Œä¸å½±éŸ¿ç²’åº¦ï¼‰
            where_parts, params = [], []
            if q:
                where_parts.append("query_protein_name = ?")
                params.append(q)
            if epi:
                where_parts.append("mme_query = ?")
                params.append(epi)
            where_sql = "WHERE " + " AND ".join(where_parts) if where_parts else ""

            # ä»¥ã€Œepitopeï¼ˆmme_queryï¼‰ã€ç‚ºå”¯ä¸€ç²’åº¦çš„èšåˆ
            # epitope_count                   = è©² epitope çš„åˆ—æ•¸ï¼ˆæˆ–æƒ³æ›´åš´æ ¼å¯æ”¹ DISTINCT hit+posï¼‰
            # hit_human_protein_id_kind      = è©² epitope å‘½ä¸­çš„ä¸åŒè›‹ç™½æ•¸
            # query_protein_name_kind        = è©² epitope ä¾†è‡ªå¹¾å€‹ä¸åŒçš„ query åç¨±
            # epitope_length                 = epitope é•·åº¦
            # IEDB_human_epitope_substring_count = å°æ‡‰ IEDB çš„ substring è¨ˆæ•¸ï¼ˆæ­¤æ¬„å°åŒä¸€ epitope é€šå¸¸ç›¸åŒï¼Œå– MAX/MIN éƒ½å¯ï¼‰
            
            sql = f"""
            WITH base AS (
            SELECT DISTINCT
                TRIM(COALESCE(mme_query,''))                 AS Epitope,
                TRIM(COALESCE(hit_human_protein_id,''))      AS hit_id,
                TRIM(COALESCE(query_protein_name,''))        AS qname,
                COALESCE(iedb_human_epitope_substring_count,0) AS substr_cnt
            FROM "{TABLE_ENR}"
            {where_sql}
            )
            SELECT
            Epitope,
            -- é€™è£¡çš„ COUNT(*) å°±æ˜¯ä»¥ base çš„ã€Œå»é‡çµæœã€è¨ˆæ•¸ï¼Œä¸æœƒè¢« *15 æ”¾å¤§
            COUNT(*)                                       AS epitope_count,
            COUNT(DISTINCT hit_id)                         AS hit_human_protein_id_kind,
            COUNT(DISTINCT qname)                          AS query_protein_name_kind,
            LENGTH(Epitope)                                AS epitope_length,
            MAX(substr_cnt)                                AS IEDB_human_epitope_substring_count
            FROM base
            GROUP BY Epitope
            ORDER BY epitope_count DESC, Epitope ASC
            { "LIMIT ?" if limit is not None else "" }
            """
            if limit is not None:
                params.append(limit)

            print("[View_by_Epitope_data] SQL:\n", sql)
            print("[View_by_Epitope_data] params:", params)

            df = pd.read_sql(sql, conn, params=params)

    except Exception as e:
        return HttpResponseBadRequest(f"è®€å–/èšåˆ SQLite å¤±æ•—ï¼š{e}")

    return JsonResponse({"columns": list(df.columns), "data": df.values.tolist()})

@require_GET
def View_by_Query_data(request):
    """
    GET åƒæ•¸ï¼š
      - ?q= æŸå€‹ query_protein_nameï¼ˆå¯é¸ï¼‰
      - ?limit= 2000ï¼ˆå¯é¸ï¼Œå°èšåˆå¾ŒçµæœåŠ  LIMITï¼‰
    å›å‚³ {columns, data} çµ¦ DataTablesã€‚
    """
    q = (request.GET.get("q") or "").strip()
    lim = request.GET.get("limit")
    limit = int(lim) if (lim and lim.isdigit()) else None

    # è¨ºæ–·ï¼ˆå¯ç•™è‘—å¹«ä½ ç¢ºèªæ˜¯ä¸æ˜¯åŒä¸€é¡† DBï¼‰
    print("[View_by_Query_data] DB exists?", Path(DB_PATH).exists(), DB_PATH)
    try:
        df = build_summary_by_query(filter_query=q if q else None, limit=limit)
    except Exception as e:
        return HttpResponseBadRequest(f"è®€å–/èšåˆ SQLite å¤±æ•—ï¼š{e}")

    return JsonResponse({
        "columns": list(df.columns),
        "data": df.values.tolist()
    })

@require_GET
def View_by_Reference_data(request):
    """
    ä»¥ hit_human_protein_id å½™ç¸½ï¼š
      - query_protein_name_kind          = COUNT(DISTINCT query_protein_name)
      - epitope_count                    = COUNT(DISTINCT TRIM(mme_query))
      - IEDB_fully_contained_MME_count   = æœ‰ fully!=0 çš„ã€Œå”¯ä¸€ epitopeã€æ•¸
      - IEDB_fully_or_partial_MME_count  = æœ‰ fully!=0 æˆ– partial!=0 çš„ã€Œå”¯ä¸€ epitopeã€æ•¸
    """
    hit_id = (request.GET.get("id") or "").strip()
    limit  = request.GET.get("limit")
    limit  = int(limit) if (limit and str(limit).isdigit()) else None

    params = []
    where  = ""
    if hit_id:
        where = "WHERE hit_human_protein_id = ?"
        params.append(hit_id)

    limit_clause = ""
    if limit is not None:
        limit_clause = " LIMIT ?"
        params.append(limit)

    sql = f"""
        SELECT
          hit_human_protein_id,
          COUNT(DISTINCT query_protein_name) AS query_protein_name_kind,
          COUNT(DISTINCT TRIM(mme_query))    AS epitope_count,
          MIN(iedb_human_protein_data_count) AS IEDB_human_protein_data_count,
          COUNT(DISTINCT CASE
                  WHEN COALESCE(iedb_human_positional_fully_contained,0) != 0
                  THEN TRIM(mme_query) END)  AS IEDB_fully_contained_MME_count,
          COUNT(DISTINCT CASE
                  WHEN COALESCE(iedb_human_positional_fully_contained,0) != 0
                       OR COALESCE(iedb_human_positional_partial_overlap,0) != 0
                  THEN TRIM(mme_query) END)  AS IEDB_fully_or_partial_MME_count
        FROM "{TABLE_ENR}"
        {where}
        GROUP BY hit_human_protein_id
        ORDER BY hit_human_protein_id ASC
        {limit_clause}
    """

    try:
        with sqlite3.connect(DB_PATH) as conn:
            # ä¹Ÿå¯å…ˆæª¢æŸ¥æ¬„ä½æ˜¯å¦å­˜åœ¨ï¼Œé¿å…æ‰“éŒ¯æ¬„ä½åï¼š
            # cols = [r[1] for r in conn.execute(f'PRAGMA table_info("{TABLE_ENR}")')]
            # print("columns:", cols)
            df = pd.read_sql(sql, conn, params=params)
    except Exception as e:
        return HttpResponseBadRequest(f"è®€å–/èšåˆ SQLite å¤±æ•—ï¼š{e}")

    return JsonResponse({"columns": list(df.columns), "data": df.values.tolist()})

# ---------------------------------------------------------
# Reference çš„ detailé 
# ---------------------------------------------------------
@require_GET
def view_by_ref_detail(request):
    hp_id = (request.GET.get("id") or "").strip()   # hit_human_protein_id
    if not hp_id:
        return HttpResponseBadRequest("ç¼ºå°‘ id")

    with sqlite3.connect(DB_PATH) as conn:
        # è¡¨1ï¼šæœ€ä¸Šé¢çš„ Human Protein åŸºæœ¬è³‡è¨Š
        sql_basic = """
            SELECT 
                Uniprot_protein,
                Gene_description,
                Gene_HGNC,
                Ensembl
            FROM human_protein_detail
            WHERE Uniprot_protein = ?
            LIMIT 1
        """
        basic_df = pd.read_sql(sql_basic, conn, params=[hp_id])
        basic_info = basic_df.to_dict(orient="records")[0] if not basic_df.empty else {
            "Uniprot_protein": hp_id,
            "Gene_description": "N/A",
            "Gene_HGNC": "N/A",
            "Ensembl": "N/A"
        }

        # è¡¨2ï¼šIEDB proofed Epitope in Human Protein
        sql_proofed = f'''
            SELECT 
                "IEDB IRI",
                "Name",
                CAST("Starting Position" AS INTEGER) AS "Starting Position",
                CAST("Ending Position"   AS INTEGER) AS "Ending Position",
                "Molecule Parent",
                "Molecule Parent IRI",
                "Source Organism",
                "UniProt_ID"
            FROM "{TABLE_IEDB_PROOFED}"
            WHERE "UniProt_ID" = ?
        '''
        proofed_df = pd.read_sql(sql_proofed, conn, params=[hp_id])

        # è¡¨3ï¼šIEDB overlapped perfect match Epitope
        sql_mme = f'''
            SELECT
                mme_hit,
                CAST(mme_hit__start AS INTEGER) AS mme_start,
                CAST(mme_hit__end   AS INTEGER) AS mme_end
            FROM "{TABLE_ENR}"
            WHERE hit_human_protein_id = ?
        '''
        mme_df = pd.read_sql(sql_mme, conn, params=[hp_id])
        mme_df["mme_start"] = pd.to_numeric(mme_df["mme_start"], errors="coerce")
        mme_df["mme_end"]   = pd.to_numeric(mme_df["mme_end"],   errors="coerce")

        # å– IEDB_human_correctï¼ˆè¡¨2ï¼‰å¿…è¦æ¬„ä½
        proofed_min = proofed_df.rename(columns={
            "IEDB IRI": "IEDB_IRI",
            "Name": "IEDB_epitope",
            "Starting Position": "IEDB_start",
            "Ending Position": "IEDB_end",
        })[["IEDB_IRI", "IEDB_epitope", "IEDB_start", "IEDB_end", "UniProt_ID"]].copy()

        for col in ["IEDB_start", "IEDB_end"]:
            proofed_min[col] = pd.to_numeric(proofed_min[col], errors="coerce").astype("Int64")

        overlap_records = []
        if not mme_df.empty and not proofed_min.empty:
            for _, m in mme_df.iterrows():
                start = m["mme_start"]; end = m["mme_end"]
                if pd.isna(start) or pd.isna(end):
                    continue
                for _, p in proofed_min.iterrows():
                    s_pos = p["IEDB_start"]; e_pos = p["IEDB_end"]
                    if pd.isna(s_pos) or pd.isna(e_pos):
                        continue
                    # æ˜¯å¦é‡ç–Š
                    if not ((start <= e_pos) and (end >= s_pos)):
                        continue
                    # å®Œå…¨åŒ…å« or éƒ¨åˆ†é‡ç–Š
                    perfect = (start >= s_pos) and (end <= e_pos)
                    pos_rel = "IEDB includes Perfect_Match" if perfect else "partial overlap"
                    overlap_records.append({
                        "IEDB_IRI":              p["IEDB_IRI"],
                        "IEDB_human_protein_id": hp_id,
                        "IEDB_epitope":          p["IEDB_epitope"],
                        "IEDB_start":            int(s_pos),
                        "IEDB_end":              int(e_pos),
                        "mme_hit":               m["mme_hit"],
                        "mme_hit__start":        int(start),
                        "mme_hit__end":          int(end),
                        "position_relationship": pos_rel,
                    })

        overlap_df = pd.DataFrame(overlap_records)
        if not overlap_df.empty:
            overlap_df = overlap_df.drop_duplicates()

        overlap_columns = [
            "IEDB_IRI",
            "IEDB_human_protein_id",
            "IEDB_epitope",
            "IEDB_start",
            "IEDB_end",
            "mme_hit",
            "mme_hit__start",
            "mme_hit__end",
            "position_relationship",
        ]
        overlap_rows = overlap_df.to_dict(orient="records") if not overlap_df.empty else []

        # è¡¨4ï¼šResult Tableï¼ˆè£œå›ï¼Œä¸¦åœ¨æœ€å¾Œå– rowsï¼‰
        sql_result = f"""
            SELECT
                query_protein_name,
                COUNT(DISTINCT TRIM(mme_query)) AS epitope_count
            FROM "{TABLE_ENR}"
            WHERE hit_human_protein_id = ?
            GROUP BY query_protein_name
            ORDER BY query_protein_name
        """
        result_df = pd.read_sql(sql_result, conn, params=[hp_id]).fillna("")
        result_rows = result_df.to_dict(orient="records")

        # è¡¨5ï¼šEpitope Plot Detailï¼ˆç™½åå–® + å›ºå®šé †åºï¼‰
        # ===== è¡¨5ï¼šEpitope Plot Detailï¼ˆå‹•æ…‹æ¬„ä½ï¼Œæ’é™¤ä¸éœ€è¦çš„ï¼‰ =====
        # ç›´æ¥å¾ iedb_result æ’ˆåŒä¸€å€‹è›‹ç™½ ID çš„ 1 ç­†è³‡æ–™
        sql_enr = f'''
            SELECT *
            FROM "{TABLE_ENR}"
            WHERE hit_human_protein_id = ?
            ORDER BY ROWID DESC   -- æƒ³å–æœ€èˆŠå°±æ”¹ ASCï¼›ä¸åœ¨æ„å¯æ‹¿æ‰ ORDER BY
            LIMIT 1
        '''
        enr_df = pd.read_sql(sql_enr, conn, params=[hp_id])

        # ä¸Ÿæ‰ä¸æƒ³è¦çš„æ¬„ä½ï¼ˆæœ‰å°±ä¸Ÿï¼Œæ²’æœ‰å°±è·³éï¼‰
        cols_to_drop = [c for c in ("job", "job_id", "batch", "batch_id") if c in enr_df.columns]
        if cols_to_drop:
            enr_df = enr_df.drop(columns=cols_to_drop)

        # è½‰ç©ºå€¼ï¼Œé¿å…å‰ç«¯é¡¯ç¤º nan
        enr_df = enr_df.fillna("")

        # **æœ€å¾Œä¸€åˆ»**æ‰ç”¢ç”Ÿ columns / rowsï¼ˆé¿å…è¡¨é ­/è¡¨èº«ä¸ä¸€è‡´ï¼‰
        enr_columns = list(enr_df.columns)
        enr_rows    = enr_df.to_dict(orient="records")

    return render(request, "view_by_ref_detail.html", {
        "hp_id": hp_id,

        # è¡¨1
        "basic_info": basic_info,

        # è¡¨2ï¼ˆProofedï¼‰
        "columns": list(proofed_df.columns),
        "rows": proofed_df.fillna("").to_dict(orient="records"),

        # è¡¨3ï¼ˆOverlapï¼‰
        "overlap_columns": overlap_columns,
        "overlap_rows": overlap_rows,

        # è¡¨4ï¼ˆResultï¼‰
        "result_rows": result_rows,

        # è¡¨5ï¼ˆENR åŸå§‹ï¼‰
        "enr_columns": enr_columns,
        "enr_rows": enr_rows,
    })